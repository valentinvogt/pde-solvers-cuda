{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db(data_dir):\n",
    "    json_files = glob.glob(os.path.join(data_dir, \"*.json\"))\n",
    "    data_list = []\n",
    "\n",
    "    # Iterate through the JSON files and read them\n",
    "    for file in json_files:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            data_list.append(data)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abd_test'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"bruss\"\n",
    "run_id = \"abd_test\"\n",
    "load_dotenv()\n",
    "data_dir = os.getenv(\"DATA_DIR\")\n",
    "output_dir = os.getenv(\"OUT_DIR\")\n",
    "output_dir = os.path.join(output_dir, model, run_id)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "df0 = get_db(os.path.join(data_dir, model, run_id))\n",
    "df0['run_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0.copy()\n",
    "df = df[df['run_id'] == run_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_blowup(df, threshold=1e3):\n",
    "#     valid_rows = []\n",
    "#     for i, row in df.iterrows():\n",
    "#         ds = nc.Dataset(row[\"filename\"])\n",
    "#         data = ds.variables[\"data\"][:]\n",
    "#         if np.isfinite(data).all() and np.max(data) < threshold:\n",
    "#             valid_rows.append(row)\n",
    "#     return pd.DataFrame(valid_rows)\n",
    "\n",
    "# df = filter_blowup(df)\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_plot(\n",
    "    df, sigdigits=2, var1=\"A\", var2=\"B\", file=\"\", steady_threshold=1e-3, osc_threshold=1e-2, dev_threshold=1e-2\n",
    "):\n",
    "    \"\"\"\n",
    "    Classify runs based on behavior and plot relevant metrics (deviation, spatial or time derivative).\n",
    "    Args:\n",
    "        df: DataFrame containing run metadata.\n",
    "        sigdigits: Number of significant digits in plot titles.\n",
    "        var1, var2: Variables to label axes (e.g., A, B).\n",
    "        file: Output file to save the figure.\n",
    "        steady_threshold: Threshold for ||du/dt|| to classify as steady.\n",
    "        osc_threshold: Threshold for oscillatory behavior.\n",
    "        dev_threshold: Threshold for deviation from the steady state.\n",
    "\n",
    "    Returns:\n",
    "        Updated DataFrame with classification labels.\n",
    "    \"\"\"\n",
    "    plotting = False\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "\n",
    "    start_frame = 80  # Ignore early frames to avoid transients\n",
    "    df = df.sort_values(by=[var1, var2])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    A_count = len(df[var1].unique())\n",
    "    B_count = int(len(df) / A_count)\n",
    "\n",
    "    if plotting:\n",
    "        fig, axes = plt.subplots(A_count, B_count, figsize=(3 * B_count + 1, 5 * A_count))\n",
    "        axes = np.atleast_2d(axes)\n",
    "\n",
    "    classifications = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        # print(\"A=\", row[\"A\"], \" B=\", row[\"B\"])\n",
    "        ds = nc.Dataset(row[\"filename\"])\n",
    "        data = ds.variables[\"data\"][:]  # Assume shape [time, spatial, ...]\n",
    "        steady_state = np.zeros_like(data[0, 0, :, :])\n",
    "        steady_state[:, 0::2] = row[\"A\"]\n",
    "        steady_state[:, 1::2] = row[\"B\"] / row[\"A\"]\n",
    "\n",
    "        deviations = []\n",
    "        time_derivatives = []\n",
    "\n",
    "        du_dt = np.gradient(data[0, :, :, 0::2], row[\"dt\"], axis=0)  # Time derivative of u\n",
    "\n",
    "        for j in range(start_frame, data.shape[1]):\n",
    "            deviations.append(np.linalg.norm(data[0, j, :, :] - steady_state))\n",
    "            time_derivatives.append(np.linalg.norm(du_dt[j]))\n",
    "\n",
    "        final_dev = deviations[-1]\n",
    "        mean_dev = np.mean(deviations)\n",
    "        std_dev = np.std(time_derivatives)\n",
    "        max_derivative = np.max(time_derivatives)\n",
    "\n",
    "        # print(\"Mean deviation=\", mean_dev, \"Final deviation=\", final_dev, \"Derivative std=\", std_dev)\n",
    "\n",
    "        # New classification scheme\n",
    "        if final_dev < dev_threshold or (final_dev < 5 * dev_threshold and max_derivative < steady_threshold):\n",
    "            category = \"steady_state\"\n",
    "        elif std_dev > osc_threshold or mean_dev > dev_threshold:\n",
    "            category = \"interesting_behavior\"\n",
    "        else:\n",
    "            category = \"divergent_or_unknown\"\n",
    "        classifications.append(category)\n",
    "\n",
    "        if plotting:\n",
    "            values = time_derivatives\n",
    "            axes[i // B_count, i % B_count].plot(\n",
    "                np.arange(0, data.shape[1] - start_frame) * row[\"dt\"] * row[\"Nt\"] / row[\"n_snapshots\"],\n",
    "                values,\n",
    "            )\n",
    "            axes[i // B_count, i % B_count].set_title(\n",
    "                f\"{var1}={row[var1]:.{sigdigits}f}\\n{var2}={row[var2]:.{sigdigits}f}\\n{category}\",\n",
    "                fontsize=6,\n",
    "            )\n",
    "\n",
    "    if plotting:\n",
    "        row = df.iloc[0]\n",
    "        time = row[\"dt\"] * row[\"Nt\"]\n",
    "        fig.suptitle(\n",
    "            f\"{row['model'].capitalize()}, Nx={row['Nx']}, dx={row['dx']}, dt={row['dt']}, T={time:.2f}, Time Derivative ||du/dt||\",\n",
    "            fontsize=4 * B_count,\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)\n",
    "\n",
    "        if file != \"\":\n",
    "            fig.savefig(file, dpi=100)\n",
    "        plt.close()\n",
    "\n",
    "    df[\"category\"] = classifications\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Du = 1\n",
    "Dv = 4\n",
    "A = 5\n",
    "B = 12.5\n",
    "row = df[(df[\"Du\"] == Du) & (df[\"Dv\"] == Dv) & (df[\"A\"] == A) & (df[\"B\"] == B)].iloc[0]\n",
    "ds = nc.Dataset(row[\"filename\"])\n",
    "data = ds.variables[\"data\"][:]  # Assume shape [time, spatial, ...]\n",
    "steady_state = np.zeros_like(data[0, 0, :, :])\n",
    "steady_state[:, 0::2] = row[\"A\"]\n",
    "steady_state[:, 1::2] = row[\"B\"] / row[\"A\"]\n",
    "Nt = data.shape[1]\n",
    "deviations = []\n",
    "time_derivatives = []\n",
    "deviations_mean = []\n",
    "du_dt = np.gradient(data[0, :, :, 0::2], row[\"dt\"], axis=0)  # Time derivative of u\n",
    "print(row[\"dt\"])\n",
    "for j in range(Nt - 50, Nt):\n",
    "    u = data[0, j, :, :]\n",
    "    du = steady_state[:, :] - u\n",
    "    # print(\"min \", du.mean())\n",
    "    # print(\"mean \", du.mean())\n",
    "    # print(\"max \", du.max())\n",
    "    # print(\"std \", du.std())\n",
    "    deviations.append(np.linalg.norm(data[0, j, :, :] - steady_state))\n",
    "    deviations_mean.append((data[0, j, :, :] - steady_state).mean())\n",
    "    time_derivatives.append(np.linalg.norm(du_dt[j]))\n",
    "\n",
    "u = data[0, :, :, 0::2]\n",
    "v = data[0, :, :, 1::2]\n",
    "time_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS  SS  SS  SS  SS  SS  SS  \n",
      "SS  SS  SS  I   I   I   I   \n",
      "SS  I   I   I   I   I   I   \n",
      "I   I   I   I   I   I   I   \n",
      "I   I   I   I   I   I   I   \n",
      "I   I   I   I   I   DU  DU  \n"
     ]
    }
   ],
   "source": [
    "Du = 3\n",
    "Dv = 54\n",
    "df_filt = df[(df[\"Du\"] == Du) & (df[\"Dv\"] == Dv)]\n",
    "\n",
    "df_class = classify_and_plot(df_filt, sigdigits=2, var1=\"A\", var2=\"B\", file=\"\", steady_threshold=1, osc_threshold=1, dev_threshold=1)\n",
    "\n",
    "for A in sorted(df_class['A'].unique()):\n",
    "    for B_mult in [1.25, 1.75, 2, 2.5, 3, 4, 5]:\n",
    "        B=A*B_mult\n",
    "        cat = df_class[(df_class['A'] == A) & (df_class['B'] == B)].iloc[0]['category']\n",
    "        s = \"\"\n",
    "        if cat == \"steady_state\":\n",
    "            s = \"SS\"\n",
    "        elif cat == \"interesting_behavior\":\n",
    "            s = \"I\"\n",
    "        else:\n",
    "            s = \"DU\"\n",
    "        print(f\"{s:3}\", end=\" \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributions for A:\n",
      "  0.1: {'steady_state': 63, 'interesting_behavior': 0, 'divergent_or_unknown': 0} (total=63)\n",
      "  0.5: {'steady_state': 31, 'interesting_behavior': 32, 'divergent_or_unknown': 0} (total=63)\n",
      "  1: {'steady_state': 15, 'interesting_behavior': 48, 'divergent_or_unknown': 0} (total=63)\n",
      "  2: {'steady_state': 9, 'interesting_behavior': 54, 'divergent_or_unknown': 0} (total=63)\n",
      "  5: {'steady_state': 12, 'interesting_behavior': 51, 'divergent_or_unknown': 0} (total=63)\n",
      "  10: {'steady_state': 18, 'interesting_behavior': 41, 'divergent_or_unknown': 4} (total=63)\n",
      "\n",
      "Distributions for B_mult:\n",
      "  1.25: {'steady_state': 45, 'interesting_behavior': 9, 'divergent_or_unknown': 0} (total=54)\n",
      "  1.75: {'steady_state': 30, 'interesting_behavior': 24, 'divergent_or_unknown': 0} (total=54)\n",
      "  2: {'steady_state': 27, 'interesting_behavior': 27, 'divergent_or_unknown': 0} (total=54)\n",
      "  2.5: {'steady_state': 16, 'interesting_behavior': 38, 'divergent_or_unknown': 0} (total=54)\n",
      "  3: {'steady_state': 12, 'interesting_behavior': 42, 'divergent_or_unknown': 0} (total=54)\n",
      "  4: {'steady_state': 9, 'interesting_behavior': 44, 'divergent_or_unknown': 1} (total=54)\n",
      "  5: {'steady_state': 9, 'interesting_behavior': 42, 'divergent_or_unknown': 3} (total=54)\n",
      "\n",
      "Distributions for Du:\n",
      "  1.0: {'steady_state': 48, 'interesting_behavior': 77, 'divergent_or_unknown': 1} (total=126)\n",
      "  2.0: {'steady_state': 50, 'interesting_behavior': 75, 'divergent_or_unknown': 1} (total=126)\n",
      "  3.0: {'steady_state': 50, 'interesting_behavior': 74, 'divergent_or_unknown': 2} (total=126)\n",
      "\n",
      "Distributions for D_mult:\n",
      "  4: {'steady_state': 71, 'interesting_behavior': 55, 'divergent_or_unknown': 0} (total=126)\n",
      "  11: {'steady_state': 44, 'interesting_behavior': 82, 'divergent_or_unknown': 0} (total=126)\n",
      "  18: {'steady_state': 33, 'interesting_behavior': 89, 'divergent_or_unknown': 4} (total=126)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "Du_values = [1.0, 2.0, 3.0]\n",
    "D_mult_values = [4, 11, 18]\n",
    "A_values = [0.1, 0.5, 1, 2, 5, 10]\n",
    "B_mult_values = [1.25, 1.75, 2, 2.5, 3, 4, 5]\n",
    "\n",
    "# Initialize dictionaries to store distributions for each parameter\n",
    "category_distribution = {\n",
    "    \"A\": defaultdict(lambda: {\"steady_state\": 0, \"interesting_behavior\": 0, \"divergent_or_unknown\": 0}),\n",
    "    \"B_mult\": defaultdict(lambda: {\"steady_state\": 0, \"interesting_behavior\": 0, \"divergent_or_unknown\": 0}),\n",
    "    \"Du\": defaultdict(lambda: {\"steady_state\": 0, \"interesting_behavior\": 0, \"divergent_or_unknown\": 0}),\n",
    "    \"D_mult\": defaultdict(lambda: {\"steady_state\": 0, \"interesting_behavior\": 0, \"divergent_or_unknown\": 0}),\n",
    "}\n",
    "\n",
    "# Iterate over all parameter combinations\n",
    "for Du in Du_values:\n",
    "    for D_mult in D_mult_values:\n",
    "        Dv = Du * D_mult\n",
    "        df_filt = df[(df[\"Du\"] == Du) & (df[\"Dv\"] == Dv)]\n",
    "\n",
    "        df_class = classify_and_plot(df_filt, sigdigits=2, var1=\"A\", var2=\"B\", file=\"\", steady_threshold=1, osc_threshold=1, dev_threshold=1)\n",
    "\n",
    "        # Update category distributions\n",
    "        for A in sorted(A_values):\n",
    "            for B_mult in B_mult_values:\n",
    "                B = A * B_mult\n",
    "                row = df_class[(df_class[\"A\"] == A) & (df_class[\"B\"] == B)]\n",
    "                if not row.empty:\n",
    "                    cat = row.iloc[0][\"category\"]\n",
    "                    if cat == \"steady_state\":\n",
    "                        category_distribution[\"A\"][A][\"steady_state\"] += 1\n",
    "                        category_distribution[\"B_mult\"][B_mult][\"steady_state\"] += 1\n",
    "                        category_distribution[\"Du\"][Du][\"steady_state\"] += 1\n",
    "                        category_distribution[\"D_mult\"][D_mult][\"steady_state\"] += 1\n",
    "                    elif cat == \"interesting_behavior\":\n",
    "                        category_distribution[\"A\"][A][\"interesting_behavior\"] += 1\n",
    "                        category_distribution[\"B_mult\"][B_mult][\"interesting_behavior\"] += 1\n",
    "                        category_distribution[\"Du\"][Du][\"interesting_behavior\"] += 1\n",
    "                        category_distribution[\"D_mult\"][D_mult][\"interesting_behavior\"] += 1\n",
    "                    else:\n",
    "                        category_distribution[\"A\"][A][\"divergent_or_unknown\"] += 1\n",
    "                        category_distribution[\"B_mult\"][B_mult][\"divergent_or_unknown\"] += 1\n",
    "                        category_distribution[\"Du\"][Du][\"divergent_or_unknown\"] += 1\n",
    "                        category_distribution[\"D_mult\"][D_mult][\"divergent_or_unknown\"] += 1\n",
    "\n",
    "# Print distributions for each parameter\n",
    "def print_distributions(param_name, distribution):\n",
    "    print(f\"Distributions for {param_name}:\")\n",
    "    for param_value, counts in sorted(distribution.items()):\n",
    "        total = sum(counts.values())\n",
    "        print(f\"  {param_value}: {counts} (total={total})\")\n",
    "    print(\"\")\n",
    "\n",
    "print_distributions(\"A\", category_distribution[\"A\"])\n",
    "print_distributions(\"B_mult\", category_distribution[\"B_mult\"])\n",
    "print_distributions(\"Du\", category_distribution[\"Du\"])\n",
    "print_distributions(\"D_mult\", category_distribution[\"D_mult\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
